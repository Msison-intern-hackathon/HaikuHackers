{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Hackathon - Garbage Detection\n",
    "\n",
    "Reference: https://github.com/Syed-Mehdi937/garbage_classification_model_smam/tree/main\n",
    "\n",
    "Garbage classification is a crucial task in reducing waste and managing resources effectively, which also plays a critical role in solving the water pollution issue. Our project utilizes **PyTorch** and **ResNet50** to develop a garbage classification model capable of identifying various types of waste.\n",
    "\n",
    "The model is trained to recognize six categories of garbage, namely **cardboard, glass, metal, paper, plastic**, and **general trash**. By fine-tuning the pre-trained **ResNet50** architecture with a **learning rate** of **0.00005**, we have improved the models accuracy.\n",
    "\n",
    "The implications of our garbage classification model are significant, particularly in waste management. It can help reduce the amount of waste that ends up on beaches, promote recycling, and conserve natural resources. By classifying waste effectively, we can work towards a cleaner and more sustainable environment, ultimately helping to solve the water pollution issue.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Importing Libraries\n",
    "\n",
    "These lines import necessary PyTorch libraries and modules along with some external libraries like Matplotlib (used to create visualizations) and Numpy (used for mathematical operations on arrays and matrices). \n",
    "\n",
    "It also imports some modules and classes from torchvision library. Finally, it imports the OS module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Using ResNet50 for Classification\n",
    "\n",
    "\n",
    "**ResNet50** is a deep **convolutional neural network** (CNN) architecture that is 50 layers deep. It is based on the Residual Network (ResNet) architecture, which introduced residual blocks to allow for better gradient flow during training. ResNet50 has demonstrated state-of-the-art performance on various computer vision tasks, including *image classification*, object detection, and semantic segmentation. \n",
    "\n",
    "The architecture is characterized by its use of skip connections, which allow for the network to learn residual mappings instead of directly learning the underlying mapping. \n",
    "\n",
    "ResNet50 has been pre-trained on the *ImageNet Large Scale Visual Recognition Challenge (ILSVRC)* dataset, which consists of over **1 million** labeled images covering 1,000 categories. This dataset is widely used for pre-training deep neural networks for image recognition tasks.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid activation function is a mathematical function used in deep learning models to introduce non-linearity into the model's outputs. It is commonly used as the final activation function in binary classification problems.\n",
    "\n",
    "The sigmoid function can be represented mathematically as:\n",
    "\n",
    "$f(x) = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "where $x$ is the input to the function and $f(x)$ is the output that is constrained between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load('.../garbage_classification_model_smam/models/garbage_classification.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Hyperparameters\n",
    "\n",
    "`epoch = 4` , sets the number of times the entire dataset will be passed through the model. In other words, the training process will run for 4 iterations on the entire dataset.\n",
    "\n",
    "`optimizer = torch.optim.Adam`, it selects the optimization algorithm used to update the weights of the neural network during the training process. Here, the Adam optimizer is selected. The Adam algorithm is an adaptive learning rate optimization algorithm, meaning that it automatically adjusts the learning rate during training based on the magnitude of the gradients.\n",
    "\n",
    "`learning_rate = 0.00005`, it sets the learning rate of the optimizer. This determines how fast or slow the weights of the model are updated during training. A smaller learning rate means slower convergence but more accurate results, while a larger learning rate means faster convergence but may result in lower accuracy. Here, the learning rate is set to 0.00005.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Accuracy vs Epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Matplotlib to plot the accuracy vs epochs for the training and validation sets to see a visual representation of the model's performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using it for plotting the loss vs epochs for the training and validation sets to see a visual representation of the model's performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading another model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the image cans.jpg is: metal\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = \".../garbage_classification_model_smam/pics/cans.jpg\"\n",
    "image_name = image_path.split(\"/\")[-1]\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations to be applied to the image\n",
    "transform = transforms.Compose([\n",
    "transforms.Resize((224, 224)),\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Apply the transformations to the image\n",
    "input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "# Pass the image to the model to get the predicted class\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor.to(device))\n",
    "\n",
    "# Convert the output to a probability distribution\n",
    "probs = torch.softmax(output, dim=1)\n",
    "\n",
    "# Get the predicted class\n",
    "pred_class = torch.argmax(probs).item()\n",
    "\n",
    "# Define the class names\n",
    "class_names = [\"cardboard\", \"glass\", \"metal\", \"paper\", \"plastic\", \"trash\"]\n",
    "\n",
    "# Print the predicted class and image name\n",
    "print(\"The predicted class for the image\", image_name, \"is:\", class_names[pred_class])\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
